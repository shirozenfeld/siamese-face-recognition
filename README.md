# One-Shot Facial Recognition using Siamese Neural Networks on LFW Dataset

This project implements a one-shot facial recognition system using **Siamese Neural Networks**, trained and evaluated on the **LFW-a (Labeled Faces in the Wild - aligned)** dataset. The network is inspired by Koch et al.'s 2015 paper: *"Siamese Neural Networks for One-shot Image Recognition"*, and is designed to verify whether two facial images depict the same personâ€”even when only one example per identity is available.

---

## ğŸ“‚ Project Overview

-  **One-shot Learning**: Works with extremely limited training samples per identity.
-  **Siamese Network Architecture**: Learns similarity between image pairs instead of categorical classification.
-  **Hyperparameter Tuning**: Utilizes [Optuna](https://optuna.org/) for automated, large-scale search.
-  **Data Augmentation**: Improves model robustness using controlled transforms.
-  **Real-world Evaluation**: Tested on LFW, a challenging facial dataset with high variation.

---

## ğŸ“Š Dataset: LFW-a

- **Source**: Aligned version of the LFW dataset.
- **Samples**: 13,233 facial images.
- **Pairs**: CSV-based file structure defining image pairs labeled as *same* (1) or *different* (0).
- **Train/Validation/Test Split**: Stratified and balanced, with 20% held out for validation.

---

## ğŸ—ï¸ Model Architecture

| Component           | Description                                                                 |
|--------------------|-----------------------------------------------------------------------------|
| Input              | Grayscale images (105x105, 160x160, or 200x200)                             |
| Conv Layers        | 4 convolutional blocks with ReLU + MaxPooling (kernels: 10, 7, 4, 4)         |
| Fully Connected    | 4096-unit dense layer with optional Dropout followed by a scalar output     |
| Output             | Absolute difference between embeddings â†’ sigmoid â†’ similarity score         |

---

## ğŸ› ï¸ Preprocessing & Augmentation

- **Cropping**: Removes 30px border to reduce noise.
- **Resizing**: Evaluated across 105Ã—105, 160Ã—160, and 200Ã—200.
- **Normalization**: Pixel values scaled to [-1, 1].
- **Augmentations (Train only)**:
  - `RandomHorizontalFlip`
  - `RandomRotation(Â±10Â°)`

---

## âš™ï¸ Hyperparameter Tuning (via Optuna)

| Parameter         | Range / Choices                           |
|------------------|-------------------------------------------|
| Image Size       | 105x105, 160x160, 200x200                  |
| Learning Rate    | Log-uniform [1e-6, 1e-3]                   |
| Weight Decay     | Log-uniform [1e-6, 1e-2]                   |
| Dropout Rate     | Uniform [0.0, 0.5]                         |
| Optimizer        | Adam, AdamW, RMSprop, SGD                 |
| Batch Size       | 32                                        |
| Loss Function    | Binary Cross Entropy                      |
| Regularization   | L1                                        |

---

## ğŸ§ª Results

| Resize | Train Acc | Val Acc | Test Acc | Train Loss | Val Loss | Epochs |
|--------|-----------|---------|----------|------------|----------|--------|
|105Ã—105 | 64.66%    | 63.64%  | 65.80%   | 0.6194     | 0.6242   | 36     |
|160Ã—160 | 75.91%    | 67.73%  | 68.00%   | 0.5065     | 0.5681   | 25     |
|200Ã—200 | 82.10%    | 71.82%  | 68.50%   | 0.4185     | 0.5637   | 25     |

- â±ï¸ Early stopping patience: 20 epochs
- ğŸ“‰ Best performance obtained at 200Ã—200 input size, with fastest convergence and highest generalization.

---

## ğŸ” Comparison with Koch et al. (2015)

| Feature                | Koch et al.              | Our Implementation             |
|------------------------|--------------------------|--------------------------------|
| Dataset                | Omniglot                 | LFW-a                          |
| Input Image Size       | 105Ã—105 RGB              | 105Ã—105 to 200Ã—200 grayscale   |
| Optimizer              | SGD                      | Adam, AdamW, RMSprop, SGD      |
| Pretrained Models      | Yes (in later works)     | No (trained from scratch)      |
| Accuracy (Best)        | ~92% (Omniglot)          | ~68.5% (LFW-a)                 |

---

## ğŸ§  Future Improvements

- âœ… Use pretrained backbones like **FaceNet** or **VGGFace**.
- ğŸ”„ Add **Batch Normalization** between Conv layers.
- ğŸ›ï¸ Explore **stochastic data augmentation** for variability.
- ğŸ§ª Tune **dropout and regularization** more aggressively for high-res inputs.

---

## ğŸ“ Files

- `code.ipynb` â€” Full implementation and training pipeline.
- `report.pdf` â€” Formal write-up with detailed experiments, results, and analysis.

---

## ğŸ‘¥ Authors

- Gil Ari Agmon 
- Shir Rozenfeld 

Project submitted as part of **Deep Learning â€“ Assignment 2**, Ben-Gurion University of the Negev.

---

## ğŸ›¡ï¸ License

This project is for academic use only.
